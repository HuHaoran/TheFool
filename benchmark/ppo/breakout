model = PPO(train_env, test_env)
3.15, 5.35, 12.0, 16.95, 21.75, 45.7, 43.8, 39.95, 58.85, 72.5, 63.2, 99.1, 76.0, 173.85, 108.55, 138.8, 122.1, 217.55, 220.35, 186.25, 204.7, 249.95, 212.9, 258.7, 328.9, 263.8, 258.25, 381.4, 212.35